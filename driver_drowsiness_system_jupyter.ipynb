{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "champion-fiction",
   "metadata": {},
   "source": [
    "## Driver Drowsiness Detection System\n",
    "\n",
    "- The system capture live footage of user using camera connected to the device.\n",
    "- The system will detect the face, left eye, and right eye of the user.\n",
    "- After detecting face, left eye and right eye of user, the model classifier in the system will classify if user is drowsy by classifying if both left eye and right eye of user is closed or opened.\n",
    "- User left eye and right eye is closed when model classifier in system classifies as \"0\"; user left eye and right eye is opened when model model classifier in system classifies as \"1\"\n",
    "- Score which is a value to keep track how long user has closed his/her eyes will increase if user's eyes is closed and will decrease if user's eyes is opened until the score is 0.\n",
    "- When score goes above 18, an alarm will sound and the application window will have a red rectangle blinking around the frame of the live footage.\n",
    "- The system will capture the an image of user that is in drowsy state when the score goes above 18 save the image in the same folder as the system file. File name of image is \"user_drowsy_image.jpg\".\n",
    "- User can exit the system by click the \"q\" button on their keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "biological-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From <ipython-input-1-2d2e78c22381>:77: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#import opencv(cv2) library for computer vision \n",
    "import cv2\n",
    "\n",
    "#import keras library for artificial neural networks or model trained with deep learning\n",
    "from keras.models import load_model\n",
    "\n",
    "#python module pygame import mixer module for loading and playing audio file\n",
    "from pygame import mixer\n",
    "\n",
    "#initialize the mixer module\n",
    "mixer.init()\n",
    "\n",
    "#load the alarm audio file with mixer module according to directory of audio file\n",
    "sound = mixer.Sound('Drowsiness detection/alarm.wav')\n",
    "\n",
    "#load pre-trained model for face detection, left eye detection and right eye detection\n",
    "face = cv2.CascadeClassifier('Drowsiness detection/haar cascade files\\haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier('Drowsiness detection/haar cascade files\\haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier('Drowsiness detection/haar cascade files\\haarcascade_righteye_2splits.xml')\n",
    "\n",
    "#load pre-trained deep learning model for drowsiness detection\n",
    "model = load_model('Drowsiness detection/models/cnncat2.h5')\n",
    "\n",
    "#get current working directory of a process or current directory of file\n",
    "path = os.getcwd()\n",
    "\n",
    "#instantiate a object for video capture module of OpenCV library for video capture live footage from primary camera device\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#instantiate a font from OpenCV library\n",
    "font = cv2.FONT_HERSHEY_TRIPLEX\n",
    "\n",
    "#initialize varaible for score, thicc(thickness of rectangle border) and array to store the state of left eye and right eye\n",
    "score=0\n",
    "thicc=2\n",
    "rpred=[99]\n",
    "lpred=[99]\n",
    "\n",
    "#capture live video footage from camera and detect user's face, left eye and right eye and determine if the user is drowsy or not\n",
    "while(True):\n",
    "    #get video footage captured by camera and initialize variable to store each frame of video footage\n",
    "    ret, frame = cap.read()\n",
    "    height,width = frame.shape[:2]\n",
    "    #convert RGB/BGR colour space to grayscale for image segmentation\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #apply pre-defined model to detect face of person to create region of interest\n",
    "    faces = face.detectMultiScale(gray,minNeighbors=5,scaleFactor=1.1,minSize=(25,25))\n",
    "    #apply pre-defined model to detect left eye and right eye of person from region of interest generated\n",
    "    left_eye = leye.detectMultiScale(gray)\n",
    "    right_eye = reye.detectMultiScale(gray)\n",
    "    #draw a rectangle on the frame/video footage as video footage captured by camera is displayed on application as\n",
    "    #the background of the text\n",
    "    cv2.rectangle(frame, (0,height-50) , (280,height) , (0,0,0) , thickness=cv2.FILLED )\n",
    "    \n",
    "    #create rectangle on the area of face of person that is detected by the classifier\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 3)\n",
    "        \n",
    "    #detect right eye of person from the region of interest generated which is the face of user    \n",
    "    for (x,y,w,h) in right_eye:\n",
    "        #draw rectangle around the right eye that is detected from the face of person\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 2)\n",
    "        #get right eye of person\n",
    "        r_eye=frame[y:y+h,x:x+w]\n",
    "        #convert rgb colour space of right eye image to grayscale\n",
    "        r_eye = cv2.cvtColor(r_eye,cv2.COLOR_BGR2GRAY)\n",
    "        #resize right eye image to 24*24 pixels\n",
    "        r_eye = cv2.resize(r_eye,(24,24))\n",
    "        #normalize the image of right eye data to be between value 0-1\n",
    "        r_eye= r_eye/255\n",
    "        r_eye= r_eye.reshape(24,24,-1)\n",
    "        r_eye = np.expand_dims(r_eye,axis=0)\n",
    "        #predict if right eye is closed using pre-trained CNN model\n",
    "        rpred = model.predict_classes(r_eye)\n",
    "        break\n",
    "        \n",
    "    #detect left eye of person from the region of interest generated which is the face of user  \n",
    "    for (x,y,w,h) in left_eye:\n",
    "        #draw rectangle around the left eye that is detected from the face of person\n",
    "        cv2.rectangle(frame, (x,y) , (x+w,y+h) , (100,100,100) , 2)\n",
    "        #get left eye of person\n",
    "        l_eye=frame[y:y+h,x:x+w]\n",
    "        #convert rgb colour space of left eye image to grayscale\n",
    "        l_eye = cv2.cvtColor(l_eye,cv2.COLOR_BGR2GRAY)\n",
    "        #resize right eye image to 24*24 pixels\n",
    "        l_eye = cv2.resize(l_eye,(24,24))\n",
    "        #normalize the image of right eye data to be between value 0-1\n",
    "        l_eye= l_eye/255\n",
    "        l_eye=l_eye.reshape(24,24,-1)\n",
    "        l_eye = np.expand_dims(l_eye,axis=0)\n",
    "        #predict if left eye is closed using pre-trained CNN model\n",
    "        lpred = model.predict_classes(l_eye)\n",
    "        break\n",
    "        \n",
    "    \"\"\"if pre-trained CNN model detected and determined both left eye and right eye is closed or predicted as \"0\", \n",
    "    score increases and text displayed on application window will change to \"Closed\" \"\"\"\n",
    "    if(rpred[0]==0 and lpred[0]==0):\n",
    "        if score < 30:\n",
    "            score= score+1\n",
    "        text = \"Closed\"\n",
    "    #if pre-trained CNN model detected and determined both left eye and right eye is open or predicted as \"1\", \n",
    "    #score decreases and text displayed on application window will change to \"Open\"\n",
    "    else:\n",
    "        score= score-1\n",
    "        text = \"Open\"\n",
    "    #change score back to zero if score decreases below zero\n",
    "    if(score<0):\n",
    "        score=0\n",
    "    #display \"Score: \" on application windows to display score of left eye and right eye to determine if user is drowsy and fall asleep\n",
    "    cv2.putText(frame, text +' Score:'+str(score),(10,height-20), font, 1,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    #when score is over 18, determines that user is drowsy and falling asleep while driving\n",
    "    if(score>18):\n",
    "        #person is feeling sleepy and the alarm audio is sounded to wake user\n",
    "        try:\n",
    "            sound.play()\n",
    "        except: # isplaying = False\n",
    "            pass\n",
    "        #increase thickness of red border that flashes around frame of captured live video footage when the system detect user falling asleep\n",
    "        if(thicc<16):\n",
    "            thicc= thicc+2\n",
    "        #decreases thickness of red border that flashes around frame of captured live video footage to stop border thickness from increasing\n",
    "        else:\n",
    "            thicc=thicc-2\n",
    "            if(thicc<2):\n",
    "                thicc=2\n",
    "        #draw rectangle border around entire frame of live video footage captured by camera if user is drowsy and fallin asleep \n",
    "        cv2.rectangle(frame,(0,0),(width,height),(0,0,255),thicc)\n",
    "        #capture image of user when user system determine user is drowsy\n",
    "        if(score == 19 and rpred[0]==0 and lpred[0]==0):\n",
    "            cv2.imwrite(os.path.join(path,'user_drowsy_image.jpg'),frame)\n",
    "            \n",
    "    #display frame of live video footage captured by camera\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    #close/stop application showing live footage captured by camera when the key \"q\" is entered\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "#interrupt stop capturing video footage from camera and close/destroy the application windowdisplaying captured live footage\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-replica",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
